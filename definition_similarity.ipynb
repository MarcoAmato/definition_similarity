{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "First of all we need to read the definitions for each word from the file `definitions.tsv` and store them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea6ba24719f2851"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from typing import Dict, List\n",
    "\n",
    "from resources.constants import punctuation, stop_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.213379Z",
     "start_time": "2024-03-12T11:06:28.192754Z"
    }
   },
   "id": "70bd309cb107a240",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.229051Z",
     "start_time": "2024-03-12T11:06:28.215573Z"
    }
   },
   "outputs": [],
   "source": [
    "definitions = pd.read_csv('resources/definitions.tsv', sep='\\t')\n",
    "definitions.head()\n",
    "\n",
    "# remove index from the dataframe (for each row it is the first element)\n",
    "definitions = definitions.iloc[:, 1:]\n",
    "definitions.head()\n",
    "\n",
    "# convert the dataframe to a dictionary for easier access\n",
    "definitions_dict: Dict[str, List[str]] = {}\n",
    "for column in definitions.columns:\n",
    "    definitions_dict[column] = definitions[column].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- DOOR: \n",
      "\tA construction used to divide two rooms, temporarily closing the passage between them\n",
      "- LADYBUG: \n",
      "\tsmall flying insect, typically red with black spots with six legs\n",
      "- PAIN: \n",
      "\tA feeling of physical or mental distress\n",
      "- BLURRINESS: \n",
      "\tsight out of focus\n"
     ]
    }
   ],
   "source": [
    "# print every word and one of its definitions\n",
    "for word in definitions_dict:\n",
    "    print(f'- {word.upper()}: \\n\\t{definitions_dict[word][0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.260399Z",
     "start_time": "2024-03-12T11:06:28.250187Z"
    }
   },
   "id": "4d17632ceb6da109",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_word_list(word_list: List[str]):\n",
    "    # remove punctuation\n",
    "    word_list = [word for word in word_list if word not in punctuation]\n",
    "    # remove stop words\n",
    "    word_list = [word for word in word_list if word not in stop_words]\n",
    "    # lemmatize the words\n",
    "    word_list = [lemmatizer.lemmatize(word) for word in word_list]\n",
    "    return word_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.275619Z",
     "start_time": "2024-03-12T11:06:28.265492Z"
    }
   },
   "id": "d0fb542409eb099b",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sentence_similarity(sentence1: str, sentence2: str):\n",
    "    # split the definitions into words\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "    words1 = clean_word_list(words1)\n",
    "    words2 = clean_word_list(words2)\n",
    "    # compute the intersection of the two definitions\n",
    "    intersection = len(set(words1).intersection(set(words2)))\n",
    "    # return the similarity, dividing by the length of the smaller definition\n",
    "    return intersection / min(len(words1), len(words2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.291329Z",
     "start_time": "2024-03-12T11:06:28.277768Z"
    }
   },
   "id": "9b16f09ef5f4204a",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def definition_similarity(word: str) -> float:\n",
    "    # if the word is not in the dictionary, raise error\n",
    "    if word not in definitions_dict:\n",
    "        raise ValueError(f'Word {word} not found in the dictionary')\n",
    "    # get word definitions\n",
    "    word_definitions = definitions_dict[word]\n",
    "    similarities: List[float] = []\n",
    "    # compute the similarity between each pair of definitions\n",
    "    for i in range(len(word_definitions)):\n",
    "        for j in range(i+1, len(word_definitions)):\n",
    "            def1 = word_definitions[i]\n",
    "            def2 = word_definitions[j]\n",
    "            similarities.append(sentence_similarity(def1, def2))\n",
    "    return sum(similarities) / len(similarities)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.306203Z",
     "start_time": "2024-03-12T11:06:28.294611Z"
    }
   },
   "id": "5ec2ec34dd74efcd",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities for word door: 0.1457782350286356\n"
     ]
    }
   ],
   "source": [
    "# try on first word\n",
    "word1 = list(definitions_dict.keys())[0]\n",
    "similarities = definition_similarity(word1)\n",
    "print(f'Similarities for word {word1}: {similarities}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.352822Z",
     "start_time": "2024-03-12T11:06:28.308387Z"
    }
   },
   "id": "2a951db9fe43e01a",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- DOOR: \n",
      "\t0.1457782350286356\n",
      "- LADYBUG: \n",
      "\t0.3663837790561933\n",
      "- PAIN: \n",
      "\t0.14762269658821392\n",
      "- BLURRINESS: \n",
      "\t0.06509760992519609\n"
     ]
    }
   ],
   "source": [
    "# go for all words\n",
    "similarities = {}\n",
    "for word in definitions_dict:\n",
    "    similarities[word] = definition_similarity(word)\n",
    "\n",
    "for word in similarities:\n",
    "    print(f'- {word.upper()}: \\n\\t{similarities[word]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:08:17.976651Z",
     "start_time": "2024-03-12T11:08:17.855801Z"
    }
   },
   "id": "64112eea0a2d3dd2",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity for concrete words: 0.25608100704241443\n",
      "Mean similarity for abstract words: 0.106360153256705\n"
     ]
    }
   ],
   "source": [
    "# get mean of concrete concepts and abstract concepts\n",
    "concrete_words = ['door', 'ladybug']\n",
    "abstract_words = ['pain', 'blurriness']\n",
    "\n",
    "concrete_similarities = [similarities[word] for word in concrete_words]\n",
    "abstract_similarities = [similarities[word] for word in abstract_words]\n",
    "\n",
    "concrete_mean = sum(concrete_similarities) / len(concrete_similarities)\n",
    "abstract_mean = sum(abstract_similarities) / len(abstract_similarities)\n",
    "\n",
    "print(f'Mean similarity for concrete words: {concrete_mean}')\n",
    "print(f'Mean similarity for abstract words: {abstract_mean}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:10:40.947098Z",
     "start_time": "2024-03-12T11:10:40.914431Z"
    }
   },
   "id": "cd965a0eebdb06a5",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity for specific words: 0.2157406944906947\n",
      "Mean similarity for general words: 0.14670046580842477\n"
     ]
    }
   ],
   "source": [
    "# get mean of words with same specificity\n",
    "specific_words = ['ladybug', 'blurriness']\n",
    "general_words = ['door', 'pain']\n",
    "\n",
    "specific_similarities = [similarities[word] for word in specific_words]\n",
    "general_similarities = [similarities[word] for word in general_words]\n",
    "\n",
    "specific_mean = sum(specific_similarities) / len(specific_similarities)\n",
    "general_mean = sum(general_similarities) / len(general_similarities)\n",
    "\n",
    "print(f'Mean similarity for specific words: {specific_mean}')\n",
    "print(f'Mean similarity for general words: {general_mean}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:12:19.495238Z",
     "start_time": "2024-03-12T11:12:19.479088Z"
    }
   },
   "id": "87a6d3a49c9905f4",
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
