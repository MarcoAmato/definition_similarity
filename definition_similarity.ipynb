{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Lexical overlap measurement\n",
    "\n",
    "1. Read the definitions for each word from the file `definitions.tsv` and store them.\n",
    "2. Create a function that computes the similarity between two definitions of a word.\n",
    "    - For each definition remove punctuation and stop words and lemmatize the words before computing the similarity.\n",
    "    - The similarity is the number of lemmas that are in common between the two definitions (overlap) divided by the length of the smaller definition.\n",
    "3. Create a function that computes the mean similarity between each pair of definitions for a given word.\n",
    "4. For each word compute the mean similarity between all pairs of definitions of the word.\n",
    "5. Compute the mean similarity for concrete concepts and abstract concepts.\n",
    "6. Compute the mean similarity for specific concepts and general concepts."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6177bd2ac4d19e84"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from typing import Dict, List\n",
    "\n",
    "from resources.constants import punctuation, stop_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.213379Z",
     "start_time": "2024-03-12T11:06:28.192754Z"
    }
   },
   "id": "70bd309cb107a240",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read the definitions\n",
    "\n",
    "Read the definitions for each word from the file `definitions.tsv` and convert them to a dictionary of the form `word: [definition1, definition2, ...]`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7416fcc34cd49dc4"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "637cf142891708ef",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "definitions = pd.read_csv('resources/definitions.tsv', sep='\\t')\n",
    "definitions.head()\n",
    "\n",
    "# remove index from the dataframe (for each row it is the first element)\n",
    "definitions = definitions.iloc[:, 1:]\n",
    "definitions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary for easier access\n",
    "definitions_dict: Dict[str, List[str]] = {}\n",
    "for column in definitions.columns:\n",
    "    definitions_dict[column] = definitions[column].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-12T11:06:28.215573Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- DOOR: \n",
      "\tA construction used to divide two rooms, temporarily closing the passage between them\n",
      "- LADYBUG: \n",
      "\tsmall flying insect, typically red with black spots with six legs\n",
      "- PAIN: \n",
      "\tA feeling of physical or mental distress\n",
      "- BLURRINESS: \n",
      "\tsight out of focus\n"
     ]
    }
   ],
   "source": [
    "# print every word and one of its definitions\n",
    "for word in definitions_dict:\n",
    "    print(f'- {word.upper()}: \\n\\t{definitions_dict[word][0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.260399Z",
     "start_time": "2024-03-12T11:06:28.250187Z"
    }
   },
   "id": "4d17632ceb6da109",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions to compute similarity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad29a37f559d5093"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean the word list by removing punctuation, stop words and lemmatizing the words."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a924cbbfd2cab008"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_word_list(word_list: List[str]):\n",
    "    # remove punctuation\n",
    "    word_list = [word for word in word_list if word not in punctuation]\n",
    "    # remove stop words\n",
    "    word_list = [word for word in word_list if word not in stop_words]\n",
    "    # lemmatize the words\n",
    "    word_list = [lemmatizer.lemmatize(word) for word in word_list]\n",
    "    return word_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.275619Z",
     "start_time": "2024-03-12T11:06:28.265492Z"
    }
   },
   "id": "d0fb542409eb099b",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute the similarity between two sentences as the number of lemmas that are in common between the two sentences divided by the length of the smaller sentence."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ba5cf6f88c62d04"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sentence_similarity(sentence1: str, sentence2: str):\n",
    "    # split the definitions into words\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "    words1 = clean_word_list(words1)\n",
    "    words2 = clean_word_list(words2)\n",
    "    # compute the intersection of the two definitions\n",
    "    intersection = len(set(words1).intersection(set(words2)))\n",
    "    # return the similarity, dividing by the length of the smaller definition\n",
    "    return intersection / min(len(words1), len(words2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.291329Z",
     "start_time": "2024-03-12T11:06:28.277768Z"
    }
   },
   "id": "9b16f09ef5f4204a",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute the mean similarity between each pair of definitions for a given word."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16a9dc3fbe9480d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def definition_similarity(word: str) -> float:\n",
    "    # if the word is not in the dictionary, raise error\n",
    "    if word not in definitions_dict:\n",
    "        raise ValueError(f'Word {word} not found in the dictionary')\n",
    "    # get word definitions\n",
    "    word_definitions = definitions_dict[word]\n",
    "    similarities: List[float] = []\n",
    "    # compute the similarity between each pair of definitions\n",
    "    for i in range(len(word_definitions)):\n",
    "        for j in range(i+1, len(word_definitions)):\n",
    "            def1 = word_definitions[i]\n",
    "            def2 = word_definitions[j]\n",
    "            similarities.append(sentence_similarity(def1, def2))\n",
    "    return sum(similarities) / len(similarities)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.306203Z",
     "start_time": "2024-03-12T11:06:28.294611Z"
    }
   },
   "id": "5ec2ec34dd74efcd",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute mean similarities for each word\n",
    "\n",
    "Try the functions on a single word."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d18fce3eddca76b0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities for word door: 0.1457782350286356\n"
     ]
    }
   ],
   "source": [
    "# try on first word\n",
    "word1 = list(definitions_dict.keys())[0]\n",
    "similarity = definition_similarity(word1)\n",
    "print(f'Average similarity for word {word1}: {similarity}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:06:28.352822Z",
     "start_time": "2024-03-12T11:06:28.308387Z"
    }
   },
   "id": "2a951db9fe43e01a",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each word compute the mean similarity between all pairs of definitions of the word."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f0aadeb91546f38"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- DOOR: \n",
      "\t0.1457782350286356\n",
      "- LADYBUG: \n",
      "\t0.3663837790561933\n",
      "- PAIN: \n",
      "\t0.14762269658821392\n",
      "- BLURRINESS: \n",
      "\t0.06509760992519609\n"
     ]
    }
   ],
   "source": [
    "similarities = {}\n",
    "for word in definitions_dict:\n",
    "    similarities[word] = definition_similarity(word)\n",
    "\n",
    "for word in similarities:\n",
    "    print(f'- {word.upper()}: \\n\\t{similarities[word]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:08:17.976651Z",
     "start_time": "2024-03-12T11:08:17.855801Z"
    }
   },
   "id": "64112eea0a2d3dd2",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the mean similarity for concrete and abstract concepts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a12ddaba2a6c65d8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity for concrete words: 0.25608100704241443\n",
      "Mean similarity for abstract words: 0.106360153256705\n"
     ]
    }
   ],
   "source": [
    "concrete_words = ['door', 'ladybug']\n",
    "abstract_words = ['pain', 'blurriness']\n",
    "\n",
    "concrete_similarities = [similarities[word] for word in concrete_words]\n",
    "abstract_similarities = [similarities[word] for word in abstract_words]\n",
    "\n",
    "concrete_mean = sum(concrete_similarities) / len(concrete_similarities)\n",
    "abstract_mean = sum(abstract_similarities) / len(abstract_similarities)\n",
    "\n",
    "print(f'Mean similarity for concrete words: {concrete_mean}')\n",
    "print(f'Mean similarity for abstract words: {abstract_mean}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:10:40.947098Z",
     "start_time": "2024-03-12T11:10:40.914431Z"
    }
   },
   "id": "cd965a0eebdb06a5",
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the mean similarity for specific and general concepts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db0e1d54fac0f19f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity for specific words: 0.2157406944906947\n",
      "Mean similarity for general words: 0.14670046580842477\n"
     ]
    }
   ],
   "source": [
    "specific_words = ['ladybug', 'blurriness']\n",
    "general_words = ['door', 'pain']\n",
    "\n",
    "specific_similarities = [similarities[word] for word in specific_words]\n",
    "general_similarities = [similarities[word] for word in general_words]\n",
    "\n",
    "specific_mean = sum(specific_similarities) / len(specific_similarities)\n",
    "general_mean = sum(general_similarities) / len(general_similarities)\n",
    "\n",
    "print(f'Mean similarity for specific words: {specific_mean}')\n",
    "print(f'Mean similarity for general words: {general_mean}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T11:12:19.495238Z",
     "start_time": "2024-03-12T11:12:19.479088Z"
    }
   },
   "id": "87a6d3a49c9905f4",
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
